[tool.poetry]
name = "llama_index_workflow_agent_base"
version = "0.1.0"
description = "A template for a LlamaIndex LLM app deployable on RHOAI Cloud as an ai_service. This particular example focues on an AutoX chatbot enhanced with external tools (function calling)."
authors = ["Your Name <you@example.com>"]
license = "MIT"
packages = [
    { include = "llama_index_workflow_agent_base", from = "src" }
]


[tool.poetry.dependencies]
python = ">=3.12, <3.14"
fastapi = ">=0.132.0"
uvicorn = {extras = ["standard"], version = ">=0.41.0"}
llama-index-llms-openai-like = ">=0.5.3"
llama-index-llms-openai = ">=0.6.19"
llama-index = ">=0.14.15"
llama-index-core = ">=0.14.15"
llama-index-utils-workflow = ">=0.5.2"
llama-stack = ">=0.5.0"
openai = ">=2.23.0"
numpy = ">=2.4.2"
milvus-lite = ">=2.5.1"
pymilvus = ">=2.6.8"
setuptools = ">=80.9.0,<82.0.0"
python-dotenv = ">=1.2.1"
nest-asyncio = ">=1.6.0"

[tool.poetry.group.dev]
optional = true

[tool.poetry.group.dev.dependencies]
pytest = "^8.3.3"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
